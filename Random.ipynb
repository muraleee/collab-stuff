{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZuUqd3KC3VplCM4jLCAjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muraleee/collab-stuff/blob/main/Random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o3JwyBHyIUU"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")  #1\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")   #1\n",
        "\n",
        "input_text = '''\n",
        "After a long day at work, Sarah decided to relax by taking her\n",
        "dog for a walk in the park. As they strolled along the\n",
        "tree-lined paths, Sarah's dog, Max, eagerly sniffed around,\n",
        "chasing after squirrels and birds. Sarah smiled as she watched\n",
        "Max enjoy himself, feeling grateful for the companionship and\n",
        "joy that her furry friend brought into her life.'''\n",
        "\n",
        "tokens = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)  #2\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state  #3\n",
        "print(\"Token embeddings:\")  #4\n",
        "for token, embedding in zip(tokens[\"input_ids\"][0],\n",
        "                            last_hidden_states[0]):\n",
        "    word = tokenizer.decode(int(token))\n",
        "    print(f\"{word}: {embedding}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=5, random_state=42)  #1\n",
        "embeddings_tsne = tsne.fit_transform(last_hidden_states[0])   #1\n",
        "\n",
        "plt.figure(figsize=(10, 8))  #2\n",
        "plt.scatter(embeddings_tsne[:, 0],   #2\n",
        "            embeddings_tsne[:, 1], marker='o')   #2\n",
        "for i, word in enumerate(tokenizer.convert_ids_to_tokens(   #2\n",
        "    tokens[\"input_ids\"][0])):   #2\n",
        "    plt.annotate(word, xy=(embeddings_tsne[i, 0],   #2\n",
        "                           embeddings_tsne[i, 1]),   #2\n",
        "                 fontsize=10)   #2\n",
        "plt.xlabel('t-SNE Dimension 1') #2\n",
        "plt.ylabel('t-SNE Dimension 2') #2\n",
        "plt.title('t-SNE Visualization of Token Embeddings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_fxsgbYPoau5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,3,4,5,6,7,8,9]\n",
        "b = map(lambda x: x*x, a)\n",
        "b = list(b)\n",
        "for i, j in zip(a,b):\n",
        "  print(i, j)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vHccHMBFyJzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "input_text = '''\n",
        "After a long day at work, Sarah decided to relax by taking her\n",
        "dog for a walk in the park. As they strolled along the\n",
        "tree-lined paths, Sarah's dog, Max, eagerly sniffed around,\n",
        "chasing after squirrels and birds. Sarah smiled as she watched\n",
        "Max enjoy himself, feeling grateful for the companionship and\n",
        "joy that her furry friend brought into her life.'''\n",
        "\n",
        "tokens = tokenizer(input_text, return_tensors=\"pt\")\n",
        "embeddings = model.embeddings  #1\n",
        "positional_embeddings = embeddings.position_embeddings.weight  #2\n",
        "position_ids = torch.arange(tokens['input_ids'].size(1),\n",
        "                            dtype=torch.long).unsqueeze(0)  #3\n",
        "input_positional_embeddings = positional_embeddings[position_ids]  #4\n",
        "\n",
        "print(\"Positional embeddings shape:\", input_positional_embeddings.shape)\n",
        "print(\"Positional embeddings for each token:\")\n",
        "\n",
        "for token_id, pos_embedding in zip(tokens['input_ids'][0],\n",
        "                                   input_positional_embeddings[0]):\n",
        "    token = tokenizer.decode([token_id])\n",
        "    print(f\"{token}: {pos_embedding}\")"
      ],
      "metadata": {
        "id": "3uOFyVagphod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "x = [4.5, 6, 3.2]\n",
        "y = list(map(lambda x: math.exp(x), x ))\n",
        "a = 0\n",
        "for i in y:\n",
        "  a = a + i\n",
        "z = list(map(lambda x: x/a, y))\n",
        "z"
      ],
      "metadata": {
        "id": "0Hi13v2Ip_nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n"
      ],
      "metadata": {
        "id": "4ZmnkSSPsDND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h  ~/.cache/huggingface/hub"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G6g6LaN6sIqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
      ],
      "metadata": {
        "id": "W-c8I56z2bDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "text = \"I loved the movie, it was fantastic!\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors = \"pt\")  #1\n",
        "\n",
        "outputs = model(**inputs)  #1\n",
        "# print(outputs)\n",
        "predicted_label = torch.argmax(outputs.logits)\n",
        "predicted_label"
      ],
      "metadata": {
        "id": "J141gtGu2gig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(task = 'text-classification',\n",
        "    model = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english')"
      ],
      "metadata": {
        "id": "3qagfCEz4GT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review1 = '''From the warm welcome to the exquisite dishes and impeccable\n",
        " service, dining at Gourmet Haven is an unforgettable experience that\n",
        " leaves you eager to return.'''\n",
        "\n",
        "review2 = '''Despite high expectations, our experience at Savor Bistro\n",
        " fell short; the food was bland, service was slow, and the overall\n",
        " atmosphere lacked charm, leaving us disappointed and unlikely to\n",
        " revisit.'''"
      ],
      "metadata": {
        "id": "x_k2bJmI4TbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classifier(review2))"
      ],
      "metadata": {
        "id": "RztJvOWD4y7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_classifier = pipeline(\"text-classification\",\n",
        "                               model=\"huaen/question_detection\")"
      ],
      "metadata": {
        "id": "7pArcRlxKe57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = question_classifier(\n",
        "    '''\n",
        "    started from this or that but where\n",
        "    ''')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "OngJ2SpLKl9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_classifier = pipeline(\"text-classification\",\n",
        "    model=\"papluca/xlm-roberta-base-language-detection\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A2pavU2xK4PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = language_classifier(\"lampa\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "jE-TIrtHLPD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\",\n",
        "                      model = \"google-t5/t5-base\")"
      ],
      "metadata": {
        "id": "R0NKROhJLRg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(task = 'translation_en_to_hi',\n",
        "                      model = \"google-t5/t5-base\")"
      ],
      "metadata": {
        "id": "qNH_0rl47xuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "\n",
        "model_name_or_path = \"tencent/HY-MT1.5-1.8B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\")  # You may want to use bfloat16 and/or move to GPU here\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Translate the following segment into Hindi, without additional explanation.\\n\\nRead this book and tell me what it discusses.\"},\n",
        "]\n",
        "tokenized_chat = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=False,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "outputs = model.generate(tokenized_chat.to(model.device), max_new_tokens=2048)\n",
        "output_text = tokenizer.decode(outputs[0])"
      ],
      "metadata": {
        "id": "-fR_kiCLAEkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(tokenized_chat.to(model.device), max_new_tokens=2048)\n",
        "output_text = tokenizer.decode(outputs[0])\n",
        "output_text"
      ],
      "metadata": {
        "id": "IbBjfAp17fas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "i9AoezXz-dE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install protobuf"
      ],
      "metadata": {
        "id": "Y9HQHYKQ_CuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "zero_shot_classifier = pipeline(\"zero-shot-classification\",\n",
        "                                model='joeddav/xlm-roberta-large-xnli')"
      ],
      "metadata": {
        "id": "4dxqxmFC_ekX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = '''\n",
        "\"In the intricate realm of global affairs, the interplay of power,\n",
        "diplomacy, and governance stands as a defining force in the\n",
        "trajectory of nations. Amidst fervent debates in legislative\n",
        "chambers and pivotal dialogues among world leaders, ideologies\n",
        "clash and policies take shape, shaping the course of societies.\n",
        "Issues such as economic disparity, environmental stewardship, and\n",
        "human rights take precedence, driving conversations and shaping\n",
        "public sentiment. In an age of digital interconnectedness, social\n",
        "media platforms have emerged as influential channels for discourse\n",
        "and activism, amplifying voices and reshaping narratives with\n",
        "remarkable speed and breadth. As citizens grapple with the\n",
        "complexities of contemporary governance, the pursuit of accountable\n",
        "and transparent leadership remains paramount, reflecting an\n",
        "enduring quest for fairness and inclusivity in societal governance.\"\n",
        "'''\n",
        "\n",
        "text2 = '''\n",
        "In the tender tapestry of human connection, romance weaves its\n",
        "delicate threads, binding hearts in a dance of passion and longing.\n",
        "From the flutter of a first glance to the warmth of an intimate\n",
        "embrace, love blooms in the most unexpected places, transcending\n",
        "barriers of time and circumstance. In the gentle caress of a hand\n",
        "and the whispered promises of affection, two souls find solace in\n",
        "each other's embrace, navigating the complexities of intimacy with\n",
        "tender care. As the sun sets and stars illuminate the night sky,\n",
        "lovers share stolen moments of intimacy, lost in the intoxicating\n",
        "rhythm of each other's presence. In the symphony of love, every\n",
        "glance, every touch, speaks volumes of a shared bond that defies\n",
        "explanation, leaving hearts entwined in an eternal embrace.\n",
        "'''"
      ],
      "metadata": {
        "id": "GFRr_CeA_puG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = [\"technology\", \"politics\", \"business\", \"romance\"]\n",
        "prediction = zero_shot_classifier(text1,\n",
        "                                  candidate_labels,\n",
        "                                  multi_label = True)"
      ],
      "metadata": {
        "id": "UzK5uFtNADli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = zero_shot_classifier([text1, text2],\n",
        "                                  candidate_labels,\n",
        "                                  multi_label = True)\n",
        "display(pd.DataFrame(prediction).drop([\"sequence\"], axis=1))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D7XxWECuAaJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-image-classification\",\n",
        "                      model = \"openai/clip-vit-large-patch14-336\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FOtZjGxeAtQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_for_classification =  [\"airplane\", \"car\", \"train\"]\n",
        "scores = classifier(\"Emirates.png\",\n",
        "                    candidate_labels = labels_for_classification)\n",
        "pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "ulrs6TS4BEmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPPcUQSrFIu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}